{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c997bb",
   "metadata": {},
   "source": [
    "# Boosting Tree\n",
    "> 배깅과 부스팅의 차이점은 학습을 위해 사용하는 개별모델을 병렬/직렬로 구성함에 있다.  \n",
    "배깅의 경우 sub sample에 따라 개별 모델을 모두 학습시키고 결과를 투표 혹은 평균을 내어 예측한다면  \n",
    "부스팅은 **개별 모델의 학습을 순차적**으로 시키며 이전 개별 모델의 결과 중 **오분류 된 데이터 혹은 오차에 가중치 부여**  \n",
    "초기에는 동일 가중치를 갖지만 각 학습 과정을 거치며 복원 추출 시 가중치의 분포/이전 round의 오차를 고려  \n",
    "\n",
    ">> 해당모델에는 `Adaboost`, `GBM`, `Xgboost`, `lightGBM`, `catboost`가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc36154",
   "metadata": {},
   "source": [
    "## bagging 과 boosting\n",
    "<img src=\"./image/33.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae88ed",
   "metadata": {},
   "source": [
    "## Adaptive booting(Adaboost)\n",
    "> a -> f 순서로 학습이 진행 되고 있다. 각 학습 단계(round)에서 오분류 된 데이터에 가중치를 부여하고  \n",
    "다음 라운드에서 가중치가 부여 된 데이터를 잘 맞추기 위한 개별모델이 학습 된다.  \n",
    "최종 모델은 개별 모델의 결과가 합쳐져서 최종 모델링이 된다.\n",
    "\n",
    "<img src=\"./image/34.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a0c188",
   "metadata": {},
   "source": [
    "## gradient boost\n",
    "이전 round 모델의 데이터별 오류를 학습하는 모델을 사용하여 점진적으로 총 모델링 오차를 줄이는 부스팅 방법\n",
    "\n",
    "$$y = h_0(x) + error_0 $$\n",
    "$$error_0 = h_1(x) + error_1 $$\n",
    "$$error_1 = h_2(x) + error_2 $$\n",
    "$$\\vdots$$\n",
    "$$y = h_0(x) + h_1(x) + h_2(x) + \\cdots + small error $$\n",
    "\n",
    "<img src=\"./image/35.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d8cf9",
   "metadata": {},
   "source": [
    "## xgboost\n",
    "> 머신러닝 알고리즘 대회인 kaggle, KDD cup등에서 우승을 한 팀들이 xgboost를 많이 활용한 것이 알려지면서 주목받음.  \n",
    "boosting 모델에서 오류를 학습하여 다음 round에 반영시키는 것은 gadient boosting과 큰 차이가 없음.  \n",
    "다만, 학습을 위한 비용함수에 규제화 식이 추가되어 모델이 과적합 되는 것을 방지함.  \n",
    "규제화를 통해 복잡한 모델에 패널티를 부여  \n",
    "\n",
    "$$obj^{(t)} = \\sum_1^{n} l(y_i, \\hat{y}_i^{(t)}) + \\sum_{i=1}^t \\Omega(f_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47530af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보스턴 데이터 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9c128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e87dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98029a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "\n",
    "'''\n",
    "xbgoost 주요 파라메터\n",
    "\n",
    "모델 파라메터\n",
    "verbosity : round 출력결과 0=무음, 1=경고, 2=정보, 3=디버그\n",
    "n_jobs : 병렬쓰레드 구성, 로컬컴퓨터 코어 x 4 최대값\n",
    "gpu_id : GPU 연산 처리 디바이스 설정\n",
    "random_state : 랜덤시드\n",
    "missing : 결측치 처리 np.nan을 디폴트로 사용\n",
    "\n",
    "트리 파라메터\n",
    "max_depth : 트리모델 최대 깊이\n",
    "max_leaves : 트리모델 최대 잎 노드 갯수, 0=무제한 지정\n",
    "grow_policy : 트리확장 방법 0=노드와 가장 가까운 노드 분할, 1=손실함수가 최소가 되는 지점에서 분할\n",
    "gamma : 트리모델의 잎 노드 분할을 만드는 데 필요한 최소 손실 감소.\n",
    "min_child_weight : 관측치에 대한 최소 가중치 값\n",
    "subsample : 부트스트랩 샘플 비율\n",
    "colsample_bytree : 부트스트랩 컬럼 비율\n",
    "reg_alpha : L1, lasso, 0\n",
    "reg_lambda : L2, ridge, 1\n",
    "\n",
    "부스팅 파라메터\n",
    "n_estimators : 부스팅 트리 갯수, round 횟수와 같은 수\n",
    "learning_rate : round별 학습률\n",
    "booster: 부스팅 트리 모델 선택\n",
    "    gbtree\n",
    "    gblinear\n",
    "objective : 목적함수 \n",
    "    reg : squarederror\n",
    "    binary : logistic\n",
    "    multi : softmax\n",
    "    multi : softprob\n",
    "eval_metric : 모델평가함수, 목적함수에 따라 지정되어 있음\n",
    "    rmse: root mean square error\n",
    "    error: Binary classification error rate (0.5 threshold)\n",
    "    merror: Multiclass classification error rate\n",
    "early_stopping_rounds : 학습 손실값 변동 없을 시 학습 종료 라운드 횟수 설정\n",
    "callbacks : 학습 중 설정 값 전달 API\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f90d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 출력\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
