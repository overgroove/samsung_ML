{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression(선형회귀모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression 모델\n",
    "> **`Linear Regression`** 은 **예측**을 위한 **지도학습** 머신러닝 모델   \n",
    "종속변수가 존재해야하며 종속변수의 데이터가 **연속형**일 경우 사용  \n",
    "ex) 주가, 매출, 키, 몸무게, 대출금액 예측문제  \n",
    "사용해야하는 설명변수의 갯수에 따라 설명변수 하나를 사용하는 **단순회귀모델**과 설명변수 여러개를 사용하는 **다중회귀모델**로 구분  \n",
    "설명변수에 패널티를 추가한 **`Lasso`**, **`Ridge`** 모델까지 확장이 가능하다.  \n",
    ">> `y = f(x)` 의 기본적인 머신러닝 함수에서  \n",
    "`y` : 종속변수(예측하고자 하는 값, 타겟, 연속형 변수)  \n",
    "`f( )` : Linear model, 예측문제를 풀어내는 함수 혹은 모델  \n",
    "`x` : 설명변수(종속변수에 영향을 주는 데이터, feature, 연속형 혹은 이산형 변수) 로 설명이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression(회귀) 이란?\n",
    "일반적으로 선형회귀방정식이라 부름. 종속변수와 독립변수 사이의 관계를 분석할 경우 많이 사용합니다.\n",
    "\n",
    "> - 통계학 - 한 개의 독립변수와 종속변수 간 관계를 잘 설명하는 직선(회귀직선)을 추정한다. 데이터 분할 X  \n",
    "> - 머신러닝 - 모델자체에는 크게 관심을 두지 않고 예측을 위해 사용한다. 데이터 분할 O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순선형회귀모델(Simple Linear Regression)\n",
    "한 개의 독립 변수와 종속 변수 간 관계를 잘 설명하는 직선을 단순회귀모델이라고 한다.  \n",
    "\n",
    "단순회귀모델의 구조는 아래와 같습니다.  \n",
    "\n",
    "# $$ y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i  $$  \n",
    "# $$ y_i = \\hat{y}+ \\varepsilon_i  $$  \n",
    "\n",
    "> $\\beta_0$ : 절편  \n",
    "$\\beta_1$ : 기울기  \n",
    "$x_i$ : $i$ 번째 샘플의 독립변수 값  \n",
    "$y_i$ : $i$ 번째 샘플의 종속변수 값  \n",
    "$\\hat{y}_i$ : $i$ 번째 샘플의 종속변수 예측 값 ($\\hat{y}_i = \\beta_0 + \\beta_1 x_i$)  \n",
    "$\\varepsilon_i$ : $i$ 번째 샘플의 예측 오차 ($y_i - \\hat{y}_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.852699Z",
     "start_time": "2023-03-30T08:09:48.153933Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요 모듈 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.916789Z",
     "start_time": "2023-03-30T08:09:48.853924Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단순선형회귀모델의 여러가지 가정에 따른 모델링 시각화\n",
    "plt.figure(figsize=(6, 3))\n",
    "x = np.array([1, 2, 3, 3.5, 4, 5, 6])\n",
    "y = np.array([2, 3, 6, 7, 9, 10, 11])\n",
    "plt.scatter(x, y, s=20, c='black') # matplotlib 산점도 그래프\n",
    "plt.plot(x , x * 2 + 2)\n",
    "plt.plot(x , x * 2 + 1) # 선그래프 시각화 함수 x, y 순서대로 전달\n",
    "plt.plot(x , x * 2)\n",
    "plt.plot(x , x * 2 - 1)\n",
    "plt.plot(x , x * 2 - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 샘플예제에서 $f(x) = 2x$ 가 가장 데이터를 잘 설명하는 직선이 된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습(traing, fitting)\n",
    "회귀모델의 학습은 회귀모델에 포함된 계수인 $\\beta_0$ 와 $\\beta_1$을 추정한다.  \n",
    "최소자승법(least square method): 회귀모델은 오차의 제곱합을 최소화하는 방향으로 계수를 추정.  \n",
    "\n",
    "#### 비용 함수 (cost function)\n",
    "$$ Cost = {1\\over2n} \\sum_i^n{(y_i - \\hat y_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.919417Z",
     "start_time": "2023-03-30T08:09:48.917711Z"
    }
   },
   "outputs": [],
   "source": [
    "# 가정에 따른 함수 h 정의\n",
    "def h1(x):\n",
    "    return x * 2 + 2\n",
    "def h2(x):\n",
    "    return x * 2 + 1\n",
    "def h3(x):\n",
    "    return x * 2\n",
    "def h4(x):\n",
    "    return x * 2 - 1\n",
    "def h5(x):\n",
    "    return x * 2 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.922630Z",
     "start_time": "2023-03-30T08:09:48.921304Z"
    }
   },
   "outputs": [],
   "source": [
    "# 비용함수 j\n",
    "def j(x, h, y):\n",
    "    return sum((y - h(x)) ** 2) / (len(x) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.924817Z",
     "start_time": "2023-03-30T08:09:48.923572Z"
    }
   },
   "outputs": [],
   "source": [
    "# 비용함수 결과출력\n",
    "print(j(x, h1, y))\n",
    "print(j(x, h2, y))\n",
    "print(j(x, h3, y))\n",
    "print(j(x, h4, y))\n",
    "print(j(x, h5, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순선형회귀모델의 비용함수는 각 가정에 대한 비용함수의 결과의 집합이고 이를 2차원 평면상에 그려보면 2차 함수임을 확인 가능합니다.  \n",
    "<img src=\"./image/12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비용함수의 최소화, 경사하강법 (gradient decent)\n",
    "위에서 정의 된 비용함수 $ Cost = {1\\over2n} \\sum_i^n{(y_i - \\hat y_i)^2}$ 의 최소값을 찾기 위해서는 미분이 필요하다.\n",
    "\n",
    "<img src=\"./image/13.png\">\n",
    "비용함수의 미분값에 따라 추정하고자 하는 파라메터(X)를 미분값과 반대방향으로 움직이면서 비용함수의 최소값에 다다르게 함.  \n",
    "<img src=\"./image/14.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델의 평가\n",
    "선형회귀모델의 평가는 모델의 예측력, 그리고 모델의 설명력을 위한 평가방법으로 나눌 수 있습니다.  \n",
    "\n",
    "> **RMSE** : 평균제곱오차의 제곱근  \n",
    "예측모델에서 가장 많이 쓰이는 지표, 예측이 대략 평균적으로 RMSE만큼 오차가 난다고 해석합니다.\n",
    "  \n",
    "$$\\sqrt{{1\\over n}\\sum_i^n{(y_i - \\hat y_i)^2}}$$\n",
    "\n",
    "> **MAE** : 평균절대 오차  \n",
    "예측모델에서 종종 쓰이는 지표, 실제 예측값에 절대값을 씌워 예측결과 오차를 그대로 해석.  \n",
    "  \n",
    "$${1\\over n}\\sum_i^n{\\left\\vert(y_i - \\hat y_i)\\right\\vert}$$\n",
    "\n",
    "> **R2 score** : 결정계수 혹은 설명계수. 독립변수가 얼마나 종속변수를 잘 설명할 수 있는지 나타냄.  \n",
    "0과 1사이 범위에 있으며, 1에 가까울 수록 모델이 종속변수를 잘 설명한다고 해석한다.  \n",
    "일반적으로는 R2 score가 0.6 이상이여야 사용가능한 모델이라고 해석한다.\n",
    "\n",
    "<img src=\"./image/15.png\">\n",
    "\n",
    "$$SST = SSR + SSE$$  \n",
    "$$R^2 = 1 - {SSE \\over SST}$$  \n",
    "$$={SSR \\over SST}$$  \n",
    "$$={선형모형오차 \\over 전체오차}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중선형회귀모델 (Multiple Linear Regression)\n",
    "독립 변수가 둘 이상인 가장 일반적인 형태의 선형회귀모델\n",
    "  \n",
    "다중선형회귀모델의 구조는 아래와 같습니다.  \n",
    "\n",
    "# $$ y_i = \\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_p x_{i,p} + \\varepsilon_i  $$  \n",
    "\n",
    "> $\\beta_0$ : 절편  \n",
    "$\\beta_p$ : $p$번째 독립변수의 계수  \n",
    "$x_{i,p}$ : $i$ 번째 샘플의 $p$번째 독립변수 값  \n",
    "$y_i$ : $i$ 번째 샘플의 종속변수 값  \n",
    "$\\hat{y}_i$ : $i$ 번째 샘플의 종속변수 예측 값 ($\\hat{y}_i = \\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_p x_{i,p}$)  \n",
    "$\\varepsilon_i$ : $i$ 번째 샘플의 예측 오차 ($y_i - \\hat{y}_i$)\n",
    "\n",
    "행렬과 벡터를 이용한 표현으로 아래와 같이 표현이 가능합니다.\n",
    "\n",
    "# $$ y = X\\beta + \\varepsilon $$\n",
    "\n",
    "# $ y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots  \\\\ y_n\\end{pmatrix}$ $ X = \\begin{pmatrix} 1 & x_{1,1} & \\dots & x_{1,p} \\\\ 1 & x_{2,1} & \\dots & x_{2,p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n,1} & \\dots & x_{n,p}\\end{pmatrix} $ $ \\beta = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots  \\\\ \\beta_p\\end{pmatrix}$ $ \\varepsilon = \\begin{pmatrix} \\varepsilon_0 \\\\ \\varepsilon_1 \\\\ \\vdots  \\\\ \\varepsilon_n\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델학습 및 비용함수\n",
    "기본선형회귀모델과 마찬가지로 최소자승법을 사용합니다.\n",
    "\n",
    "#### 비용함수\n",
    "$$\\varepsilon = y - \\hat{y}$$  \n",
    "$$\\hat{y} = X\\beta$$  \n",
    "$$J = \\varepsilon^T\\varepsilon = (y - \\hat{y})^T(y - \\hat{y})$$  \n",
    "$$ =(y^T - \\beta^TX^T)(y - X\\beta) $$  \n",
    "$$ =y^Ty - y^TX\\beta - \\beta^TX^Ty - \\beta^TX^TX\\beta$$\n",
    "\n",
    "$$ {\\partial J \\over \\partial \\beta} = 0 \\Rightarrow \\beta = (X^TX)^{-1}X^Ty$$\n",
    "(행렬-벡터 미분 생략)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 선형 회귀 모델 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 모듈 import\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.927041Z",
     "start_time": "2023-03-30T08:09:48.925654Z"
    }
   },
   "outputs": [],
   "source": [
    "# boston 데이터 확인\n",
    "df = pd.read_csv('./data/boston.csv') # 절대경로, 축약경로를 문자열 형식으로 전달\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.929322Z",
     "start_time": "2023-03-30T08:09:48.927956Z"
    }
   },
   "outputs": [],
   "source": [
    "# 타겟데이터 분할\n",
    "y = df['y']\n",
    "X = df.drop('y', axis=1) # 열방향 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.931679Z",
     "start_time": "2023-03-30T08:09:48.930167Z"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련셋과 테스트셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# 비율 75:25 요정도 비율 괜챦음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.934012Z",
     "start_time": "2023-03-30T08:09:48.932621Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.938509Z",
     "start_time": "2023-03-30T08:09:48.936981Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.941084Z",
     "start_time": "2023-03-30T08:09:48.939638Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.943278Z",
     "start_time": "2023-03-30T08:09:48.941908Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가지표 출력\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "print(f'R2 score : {r2_score(y_test, lr_pred)}')\n",
    "print(f'RMSE : {mean_squared_error(y_test, lr_pred, squared=False)}')\n",
    "print(f'MAE : {mean_absolute_error(y_test, lr_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 해석\n",
    "# r2 : 선택한 설명변수와 모델이 보스턴주택가격의 오차 변동분을 약 71% 설명이 가능하다.\n",
    "# 0.6 이상이기에 사용가능한 모델이다.\n",
    "# RMSE : 4.6386 모델의 예측값이 실제 보스턴주택가격과 평균적으로 4.6386만달러 오차를 보임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.945418Z",
     "start_time": "2023-03-30T08:09:48.944063Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 계수 확인\n",
    "lr.intercept_, lr.coef_\n",
    "# b0, b1 2 3 4 5 6 베타값들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화 모델\n",
    "> 일반적으로 샘플 수가 변수 갯수보다 적거나 크게 많지 않다면 회귀모델은 **과적합(overfitting)** 되는 경향이 있습니다.  \n",
    "회귀모델은 종속변수와 큰 관계가 없는 변수를 없애 주지 못함(수작업 필요).   \n",
    "이를 해결하기 위하여 설명 변수가 너무 많으면 정규화(규제)를 통해 이를 해결합니다.  \n",
    "최소자승법은 $\\beta_i = 0$을 만들어주지 못함.  \n",
    "\n",
    "### 과적합(overfitting)  \n",
    "> 학습 데이터로 학습한 모델의 테스트 데이터 예측 성능이 떨어지는 경우  \n",
    "모델이 일반화를 잘 못 시키는 상태. 실제 데이터 예측을 잘 못한다고 해석이 가능합니다.\n",
    "\n",
    "<img src=\"./image/16.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso 모델\n",
    "기존 회귀모델의 비용함수에 설명변수의 베타 절대값의 합 $\\lambda\\sum_{j=1}^p\\left\\vert\\beta_j\\right\\vert$를 패널티 식으로 추가.\n",
    "$$J = \\sum_{i=1}^n{(y_i - \\hat y_i)^2} + \\lambda\\sum_{j=1}^p\\left\\vert\\beta_j\\right\\vert$$  \n",
    "\n",
    "> $n$ : 샘플갯수  \n",
    "> $p$ : 설명변수갯수  \n",
    "\n",
    "모델이 최적화 과정을 거치면서 비용함수의 최소값이 패널티 영역과 만나는 지점에서 정규화 모델의 최적이 이루어집니다.  \n",
    "회귀모델의 오차와 베타 절대값합에 해당하는 값을 동시에 최소화 시키는 방법으로 학습을 진행합니다.  \n",
    "불필요하게 설명변수의 갯수가 많을 경우 **회귀계수의 크기를 0으로 만들면서** 최적을 찾아갑니다.  \n",
    "많은 변수에 큰 패널티를 주며 독립변수의 갯수가 ridge 모델보다 상대적으로 많은 경우 Lasso 모델을 사용합니다.\n",
    "<img src=\"./image/17.png\">\n",
    "\n",
    "### Ridge 모델\n",
    "기존 회귀모델의 비용함수에 설명변수의 베타의 제곱 합을 패널티로 $\\lambda\\sum_{j=1}^p\\beta_j^2$를 패널티 식으로 추가\n",
    "$$ J = \\sum_{i=1}^n{(y_i - \\hat y_i)^2} + \\lambda\\sum_{j=1}^p\\beta_j^2$$  \n",
    "\n",
    "> $n$ : 샘플갯수  \n",
    "> $p$ : 설명변수갯수  \n",
    "\n",
    "회귀모델의 오차와 베타 제곱합에 해당하는 값을 동시에 최소화 시키면서 학습을 진행합니다.  \n",
    "불필요하게 과대계상 된 변수의 **회귀계수의 크기를 감소**시키는 방법으로 학습을 진행합니다.    \n",
    "많은 변수에 패널티를 주며 독립변수의 갯수가 Lasso 모델보다 상대적으로 작은 경우 Ridge 모델을 사용합니다.\n",
    "<img src=\"./image/18.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화 모델 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.948167Z",
     "start_time": "2023-03-30T08:09:48.946509Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 import\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.951066Z",
     "start_time": "2023-03-30T08:09:48.949084Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "# 규제화모델의 경우 파라메터로 규제화강도에 해당하는 alpha 값을 같이 전달함. \n",
    "rg = Ridge(alpha=10) # 서칭이 필요한 파라메터 1, 3, 5, 7, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.953666Z",
     "start_time": "2023-03-30T08:09:48.951963Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "rg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.955842Z",
     "start_time": "2023-03-30T08:09:48.954549Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "rg_pred = rg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.958317Z",
     "start_time": "2023-03-30T08:09:48.956668Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "print(f'R2 score : {r2_score(y_test, rg_pred)}')\n",
    "print(f'RMSE : {mean_squared_error(y_test, rg_pred, squared=False)}')\n",
    "print(f'MAE : {mean_absolute_error(y_test, rg_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "R2 score : 0.7112260057484925\n",
    "RMSE : 4.638689926172827\n",
    "MAE : 3.1627098714574147\n",
    "\n",
    "R2 score : 0.7041586727559433\n",
    "RMSE : 4.695109486461527\n",
    "MAE : 3.1785390760345575\n",
    "\n",
    "R2 score : 0.6954181695183624\n",
    "RMSE : 4.763962116024238\n",
    "MAE : 3.2491698993077893\n",
    "\n",
    "'''\n",
    "# 기존 선형회귀 모델보다 규제화 모델의 성능이 좋지 않은 상황\n",
    "# 이를 바탕으로 현재 오버피팅이 아닌 언디피팅 상황이라는 걸 파악 모델 개선 방향을 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.961220Z",
     "start_time": "2023-03-30T08:09:48.959424Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 계수 확인\n",
    "rg.intercept_, rg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.963960Z",
     "start_time": "2023-03-30T08:09:48.962293Z"
    }
   },
   "outputs": [],
   "source": [
    "# 기존모델에서의 회귀계수 와 ridge모델 계수 플로팅\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(X_train.columns, lr.coef_)\n",
    "plt.bar(X_train.columns, rg.coef_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.966477Z",
     "start_time": "2023-03-30T08:09:48.965033Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.969107Z",
     "start_time": "2023-03-30T08:09:48.967501Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.971348Z",
     "start_time": "2023-03-30T08:09:48.970000Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.973589Z",
     "start_time": "2023-03-30T08:09:48.972118Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 평가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.975941Z",
     "start_time": "2023-03-30T08:09:48.974511Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 계수 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.978566Z",
     "start_time": "2023-03-30T08:09:48.977097Z"
    }
   },
   "outputs": [],
   "source": [
    "# 계수 플로팅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다항회귀\n",
    "> 선형회귀의 경우 설명변수와 종속변수의 관계를 선형관계로 해석하지만 현실 문제는 선형으로 해결이 불가능한 경우가 많습니다.  \n",
    "선형모델의 구조적 한계를 보완하고자 **변수 간 영향력에 해당하는 새로운 변수를 생성**하여 방정식을 비선형으로 만들고 선형모델을 적용시킬 수 있습니다.  \n",
    "2차원 예시 $x_1, x_2, x_3$를 $x_1^2, x_2^2, x_3^2, x_1x_2, x_1x_3, x_2x_3$으로 변환하여 변수를 확장.  \n",
    "보통 2차원 또는 3차원까지 적용하며, 변수가 많아지므로 Ridge, Lasso 모델을 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다항회귀 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.981411Z",
     "start_time": "2023-03-30T08:09:48.979780Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요모델 import\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.990012Z",
     "start_time": "2023-03-30T08:09:48.987706Z"
    }
   },
   "outputs": [],
   "source": [
    "# 다항변수 제작함수 인스턴스화\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "'''\n",
    "파라메터\n",
    "degree=2 : 차수설정\n",
    "include_bias=False : 상수항 제거(필수)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.992669Z",
     "start_time": "2023-03-30T08:09:48.991204Z"
    }
   },
   "outputs": [],
   "source": [
    "# 변수 변환\n",
    "# X_train에 해당하는 변수를 학습과 동시에 적용\n",
    "# 학습은 X_train 설명변수의 갯수, 설명변수의 이름을 학습\n",
    "poly_X_train = poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.995493Z",
     "start_time": "2023-03-30T08:09:48.993503Z"
    }
   },
   "outputs": [],
   "source": [
    "# shape 확인\n",
    "X_train.shape, poly_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.997677Z",
     "start_time": "2023-03-30T08:09:48.996236Z"
    }
   },
   "outputs": [],
   "source": [
    "# 변환식 반환\n",
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 200\n",
    "# 판다스 최대 컬럼 표시설정 옵션값 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.999958Z",
     "start_time": "2023-03-30T08:09:48.998423Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 데이터프레임으로 제작 후 데이터 확인\n",
    "pd.DataFrame(poly_X_train, columns=poly.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:49.002463Z",
     "start_time": "2023-03-30T08:09:49.000947Z"
    }
   },
   "outputs": [],
   "source": [
    "# test 데이터 동일한 모델로 적용\n",
    "poly_X_test = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:49.004773Z",
     "start_time": "2023-03-30T08:09:49.003435Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "poly_lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:49.007241Z",
     "start_time": "2023-03-30T08:09:49.005820Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "poly_lasso.fit(poly_X_train, y_train) # 학습에 사용하는데이터는 다항 변환을 한 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:49.009714Z",
     "start_time": "2023-03-30T08:09:49.008122Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "poly_lasso_pred = poly_lasso.predict(poly_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:49.012086Z",
     "start_time": "2023-03-30T08:09:49.010719Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "print(f'R2 score : {r2_score(y_test, poly_lasso_pred)}')\n",
    "print(f'RMSE : {mean_squared_error(y_test, poly_lasso_pred, squared=False)}')\n",
    "print(f'MAE : {mean_absolute_error(y_test, poly_lasso_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''linear\n",
    "R2 score : 0.7112260057484925\n",
    "RMSE : 4.638689926172827\n",
    "MAE : 3.1627098714574147\n",
    "\n",
    "rg alpha=1\n",
    "R2 score : 0.7041586727559433\n",
    "RMSE : 4.695109486461527\n",
    "MAE : 3.1785390760345575\n",
    "\n",
    "rg alpha=10\n",
    "R2 score : 0.6954181695183624\n",
    "RMSE : 4.763962116024238\n",
    "MAE : 3.2491698993077893\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:49.014617Z",
     "start_time": "2023-03-30T08:09:49.012960Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 계수 확인\n",
    "poly_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:49.017079Z",
     "start_time": "2023-03-30T08:09:49.015501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 계수 플로팅\n",
    "plt.figure(figsize=(10, 30))\n",
    "plt.barh(poly.get_feature_names_out(), poly_lasso.coef_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다만 기존 통계가정을 모두 깨는 모델이기에 모델예측력이 최우선인 프로젝트에 사용\n",
    "# 내부 설명변수와의 관계를 분석하는 프로젝트에는 사용이 부적합함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
