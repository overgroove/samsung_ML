{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression(선형회귀모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression 모델\n",
    "> **`Linear Regression`** 은 **예측**을 위한 **지도학습** 머신러닝 모델   \n",
    "종속변수가 존재해야하며 종속변수의 데이터가 **연속형**일 경우 사용  \n",
    "ex) 주가, 매출, 키, 몸무게, 대출금액 예측문제  \n",
    "사용해야하는 설명변수의 갯수에 따라 설명변수 하나를 사용하는 **단순회귀모델**과 설명변수 여러개를 사용하는 **다중회귀모델**로 구분  \n",
    "설명변수에 패널티를 추가한 **`Lasso`**, **`Ridge`** 모델까지 확장이 가능하다.  \n",
    ">> `y = f(x)` 의 기본적인 머신러닝 함수에서  \n",
    "`y` : 종속변수(예측하고자 하는 값, 타겟, 연속형 변수)  \n",
    "`f( )` : Linear model, 예측문제를 풀어내는 함수 혹은 모델  \n",
    "`x` : 설명변수(종속변수에 영향을 주는 데이터, feature, 연속형 혹은 이산형 변수) 로 설명이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression(회귀) 이란?\n",
    "일반적으로 선형회귀방정식이라 부름. 종속변수와 독립변수 사이의 관계를 분석할 경우 많이 사용합니다.\n",
    "\n",
    "> - 통계학 - 한 개의 독립변수와 종속변수 간 관계를 잘 설명하는 직선(회귀직선)을 추정한다. 데이터 분할 X  \n",
    "> - 머신러닝 - 모델자체에는 크게 관심을 두지 않고 예측을 위해 사용한다. 데이터 분할 O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순선형회귀모델(Simple Linear Regression)\n",
    "한 개의 독립 변수와 종속 변수 간 관계를 잘 설명하는 직선을 단순회귀모델이라고 한다.  \n",
    "\n",
    "단순회귀모델의 구조는 아래와 같습니다.  \n",
    "\n",
    "# $$ y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i  $$  \n",
    "# $$ y_i = \\hat{y}+ \\varepsilon_i  $$  \n",
    "\n",
    "> $\\beta_0$ : 절편  \n",
    "$\\beta_1$ : 기울기  \n",
    "$x_i$ : $i$ 번째 샘플의 독립변수 값  \n",
    "$y_i$ : $i$ 번째 샘플의 종속변수 값  \n",
    "$\\hat{y}_i$ : $i$ 번째 샘플의 종속변수 예측 값 ($\\hat{y}_i = \\beta_0 + \\beta_1 x_i$)  \n",
    "$\\varepsilon_i$ : $i$ 번째 샘플의 예측 오차 ($y_i - \\hat{y}_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.852699Z",
     "start_time": "2023-03-30T08:09:48.153933Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요 모듈 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.916789Z",
     "start_time": "2023-03-30T08:09:48.853924Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단순선형회귀모델의 여러가지 가정에 따른 모델링 시각화\n",
    "plt.figure(figsize=(6, 3))\n",
    "x = np.array([1, 2, 3, 3.5, 4, 5, 6])\n",
    "y = np.array([2, 3, 6, 7, 9, 10, 11])\n",
    "plt.scatter(x, y, s=20, c='black')\n",
    "\n",
    "plt.plot(x, 2 * x + 2) # 선그래프 x, y 순서대로 전달 선그래프 그림\n",
    "plt.plot(x, 2 * x + 1)\n",
    "plt.plot(x, 2 * x)\n",
    "plt.plot(x, 2 * x - 1)\n",
    "plt.plot(x, 2 * x - 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 샘플예제에서 $f(x) = 2x$ 가 가장 데이터를 잘 설명하는 직선이 된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습(traing, fitting)\n",
    "회귀모델의 학습은 회귀모델에 포함된 계수인 $\\beta_0$ 와 $\\beta_1$을 추정한다.  \n",
    "최소자승법(least square method): 회귀모델은 오차의 제곱합을 최소화하는 방향으로 계수를 추정.  \n",
    "\n",
    "#### 비용 함수 (cost function)\n",
    "$$ Cost = {1\\over2n} \\sum_i^n{(y_i - \\hat y_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.919417Z",
     "start_time": "2023-03-30T08:09:48.917711Z"
    }
   },
   "outputs": [],
   "source": [
    "# 가정에 따른 함수 h 정의\n",
    "def h1(x):\n",
    "    return 2 * x + 2\n",
    "def h2(x):\n",
    "    return 2 * x + 1\n",
    "def h3(x):\n",
    "    return 2 * x\n",
    "def h4(x):\n",
    "    return 2 * x - 1\n",
    "def h5(x):\n",
    "    return 2 * x - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.922630Z",
     "start_time": "2023-03-30T08:09:48.921304Z"
    }
   },
   "outputs": [],
   "source": [
    "# 비용함수 j\n",
    "def j(x, h, y):\n",
    "    return sum((y - h(x)) ** 2) / (len(x) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.924817Z",
     "start_time": "2023-03-30T08:09:48.923572Z"
    }
   },
   "outputs": [],
   "source": [
    "# 비용함수 결과출력\n",
    "print(j(x, h1, y))\n",
    "print(j(x, h2, y))\n",
    "print(j(x, h3, y))\n",
    "print(j(x, h4, y))\n",
    "print(j(x, h5, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순선형회귀모델의 비용함수는 각 가정에 대한 비용함수의 결과의 집합이고 이를 2차원 평면상에 그려보면 2차 함수임을 확인 가능합니다.  \n",
    "<img src=\"./image/12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비용함수의 최소화, 경사하강법 (gradient decent)\n",
    "위에서 정의 된 비용함수 $ Cost = {1\\over2n} \\sum_i^n{(y_i - \\hat y_i)^2}$ 의 최소값을 찾기 위해서는 미분이 필요하다.\n",
    "\n",
    "<img src=\"./image/13.png\">\n",
    "비용함수의 미분값에 따라 추정하고자 하는 파라메터(X)를 미분값과 반대방향으로 움직이면서 비용함수의 최소값에 다다르게 함.  \n",
    "<img src=\"./image/14.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델의 평가\n",
    "선형회귀모델의 평가는 모델의 예측력, 그리고 모델의 설명력을 위한 평가방법으로 나눌 수 있습니다.  \n",
    "\n",
    "> **RMSE** : 평균제곱오차의 제곱근  \n",
    "예측모델에서 가장 많이 쓰이는 지표, 예측이 대략 평균적으로 RMSE만큼 오차가 난다고 해석합니다.\n",
    "  \n",
    "$$\\sqrt{{1\\over n}\\sum_i^n{(y_i - \\hat y_i)^2}}$$\n",
    "\n",
    "> **MAE** : 평균절대 오차  \n",
    "예측모델에서 종종 쓰이는 지표, 실제 예측값에 절대값을 씌워 예측결과 오차를 그대로 해석.  \n",
    "  \n",
    "$${1\\over n}\\sum_i^n{\\left\\vert(y_i - \\hat y_i)\\right\\vert}$$\n",
    "\n",
    "> **R2 score** : 결정계수 혹은 설명계수. 독립변수가 얼마나 종속변수를 잘 설명할 수 있는지 나타냄.  \n",
    "0과 1사이 범위에 있으며, 1에 가까울 수록 모델이 종속변수를 잘 설명한다고 해석한다.  \n",
    "일반적으로는 R2 score가 0.6 이상이여야 사용가능한 모델이라고 해석한다.\n",
    "\n",
    "<img src=\"./image/15.png\">\n",
    "\n",
    "$$SST = SSR + SSE$$  \n",
    "$$R^2 = 1 - {SSE \\over SST}$$  \n",
    "$$={SSR \\over SST}$$  \n",
    "$$={선형모형오차 \\over 전체오차}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중선형회귀모델 (Multiple Linear Regression)\n",
    "독립 변수가 둘 이상인 가장 일반적인 형태의 선형회귀모델\n",
    "  \n",
    "다중선형회귀모델의 구조는 아래와 같습니다.  \n",
    "\n",
    "# $$ y_i = \\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_p x_{i,p} + \\varepsilon_i  $$  \n",
    "\n",
    "> $\\beta_0$ : 절편  \n",
    "$\\beta_p$ : $p$번째 독립변수의 계수  \n",
    "$x_{i,p}$ : $i$ 번째 샘플의 $p$번째 독립변수 값  \n",
    "$y_i$ : $i$ 번째 샘플의 종속변수 값  \n",
    "$\\hat{y}_i$ : $i$ 번째 샘플의 종속변수 예측 값 ($\\hat{y}_i = \\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_p x_{i,p}$)  \n",
    "$\\varepsilon_i$ : $i$ 번째 샘플의 예측 오차 ($y_i - \\hat{y}_i$)\n",
    "\n",
    "행렬과 벡터를 이용한 표현으로 아래와 같이 표현이 가능합니다.\n",
    "\n",
    "# $$ y = X\\beta + \\varepsilon $$\n",
    "\n",
    "# $ y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots  \\\\ y_n\\end{pmatrix}$ $ X = \\begin{pmatrix} 1 & x_{1,1} & \\dots & x_{1,p} \\\\ 1 & x_{2,1} & \\dots & x_{2,p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n,1} & \\dots & x_{n,p}\\end{pmatrix} $ $ \\beta = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots  \\\\ \\beta_p\\end{pmatrix}$ $ \\varepsilon = \\begin{pmatrix} \\varepsilon_0 \\\\ \\varepsilon_1 \\\\ \\vdots  \\\\ \\varepsilon_n\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델학습 및 비용함수\n",
    "기본선형회귀모델과 마찬가지로 최소자승법을 사용합니다.\n",
    "\n",
    "#### 비용함수\n",
    "$$\\varepsilon = y - \\hat{y}$$  \n",
    "$$\\hat{y} = X\\beta$$  \n",
    "$$J = \\varepsilon^T\\varepsilon = (y - \\hat{y})^T(y - \\hat{y})$$  \n",
    "$$ =(y^T - \\beta^TX^T)(y - X\\beta) $$  \n",
    "$$ =y^Ty - y^TX\\beta - \\beta^TX^Ty - \\beta^TX^TX\\beta$$\n",
    "\n",
    "$$ {\\partial J \\over \\partial \\beta} = 0 \\Rightarrow \\beta = (X^TX)^{-1}X^Ty$$\n",
    "(행렬-벡터 미분 생략)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 선형 회귀 모델 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석용 패키지 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 파이썬 실행시키고 맨 윗줄 2줄은 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.927041Z",
     "start_time": "2023-03-30T08:09:48.925654Z"
    }
   },
   "outputs": [],
   "source": [
    "# boston 데이터 확인\n",
    "df = pd.read_csv('./data/boston.csv')\n",
    "df.head() # 데이터프레임의 첫 5개 샘플 확인 하는 메소드 (기능, 함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.929322Z",
     "start_time": "2023-03-30T08:09:48.927956Z"
    }
   },
   "outputs": [],
   "source": [
    "# 타겟데이터 분할\n",
    "y = df['y']\n",
    "X = df.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.931679Z",
     "start_time": "2023-03-30T08:09:48.930167Z"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련셋과 테스트셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# 분할되는 데이터셋의 순서는 고정 X 데이터, 학습 데이터 먼저\n",
    "# test_size 테스트데이터 비율을 설정하는 파라메터\n",
    "# 랜덤하게 셔플이 되어서 나뉘어 지는데 이 나뉘는 난수의 시작점을 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.934012Z",
     "start_time": "2023-03-30T08:09:48.932621Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "# 모델 클래스의 경우에는 사용가능한 객체 형태로 저장을 해주셔야 사용가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.938509Z",
     "start_time": "2023-03-30T08:09:48.936981Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.941084Z",
     "start_time": "2023-03-30T08:09:48.939638Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.943278Z",
     "start_time": "2023-03-30T08:09:48.941908Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 평가지표 출력\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "print(f'R2 score : {r2_score(y_test, lr_pred)}')\n",
    "print(f'RMSE : {mean_squared_error(y_test, lr_pred, squared=False)}') # squared=False 루트 적용한 값\n",
    "print(f'MAE : {mean_absolute_error(y_test, lr_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.711 설명변수와 모델이 보스턴주택가격의 오차 변동분을 약 71% 설명 가능하다. 60% 사용가능한 모델이다.\n",
    "# RMSE 4.63 모델의 예측오차가 평균적으로 4.63만 달러 오차를 보임 6000만원 차이가 나는데?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.945418Z",
     "start_time": "2023-03-30T08:09:48.944063Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 계수 확인\n",
    "lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베타 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(X_train.columns, lr.coef_) # 막대그래프 x, y 순서대로 전달\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베타 해석\n",
    "y = b0 + b1x1 + b2x2 .....\n",
    "# NOX 기준 베타의 해석 x5 b5 = y\n",
    "# nox가 1증가함에 따라 보스턴주택가격은 약 15만 달러 하락함\n",
    "# RM 1증가함에 다라 주택가격은 약 4만 달러 상승함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
