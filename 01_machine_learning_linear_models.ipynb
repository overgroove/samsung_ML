{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression(선형회귀모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression 모델\n",
    "> **`Linear Regression`** 은 **예측**을 위한 **지도학습** 머신러닝 모델   \n",
    "종속변수가 존재해야하며 종속변수의 데이터가 **연속형**일 경우 사용  \n",
    "ex) 주가, 매출, 키, 몸무게, 대출금액 예측문제  \n",
    "사용해야하는 설명변수의 갯수에 따라 설명변수 하나를 사용하는 **단순회귀모델**과 설명변수 여러개를 사용하는 **다중회귀모델**로 구분  \n",
    "설명변수에 패널티를 추가한 **`Lasso`**, **`Ridge`** 모델까지 확장이 가능하다.  \n",
    ">> `y = f(x)` 의 기본적인 머신러닝 함수에서  \n",
    "`y` : 종속변수(예측하고자 하는 값, 타겟, 연속형 변수)  \n",
    "`f( )` : Linear model, 예측문제를 풀어내는 함수 혹은 모델  \n",
    "`x` : 설명변수(종속변수에 영향을 주는 데이터, feature, 연속형 혹은 이산형 변수) 로 설명이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression(회귀) 이란?\n",
    "일반적으로 선형회귀방정식이라 부름. 종속변수와 독립변수 사이의 관계를 분석할 경우 많이 사용합니다.\n",
    "\n",
    "> - 통계학 - 한 개의 독립변수와 종속변수 간 관계를 잘 설명하는 직선(회귀직선)을 추정한다. 데이터 분할 X  \n",
    "> - 머신러닝 - 모델자체에는 크게 관심을 두지 않고 예측을 위해 사용한다. 데이터 분할 O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순선형회귀모델(Simple Linear Regression)\n",
    "한 개의 독립 변수와 종속 변수 간 관계를 잘 설명하는 직선을 단순회귀모델이라고 한다.  \n",
    "\n",
    "단순회귀모델의 구조는 아래와 같습니다.  \n",
    "\n",
    "# $$ y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i  $$  \n",
    "# $$ y_i = \\hat{y}+ \\varepsilon_i  $$  \n",
    "\n",
    "> $\\beta_0$ : 절편  \n",
    "$\\beta_1$ : 기울기  \n",
    "$x_i$ : $i$ 번째 샘플의 독립변수 값  \n",
    "$y_i$ : $i$ 번째 샘플의 종속변수 값  \n",
    "$\\hat{y}_i$ : $i$ 번째 샘플의 종속변수 예측 값 ($\\hat{y}_i = \\beta_0 + \\beta_1 x_i$)  \n",
    "$\\varepsilon_i$ : $i$ 번째 샘플의 예측 오차 ($y_i - \\hat{y}_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.852699Z",
     "start_time": "2023-03-30T08:09:48.153933Z"
    }
   },
   "outputs": [],
   "source": [
    "# 필요 모듈 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.916789Z",
     "start_time": "2023-03-30T08:09:48.853924Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단순선형회귀모델의 여러가지 가정에 따른 모델링 시각화\n",
    "plt.figure(figsize=(6, 3))\n",
    "x = np.array([1, 2, 3, 3.5, 4, 5, 6])\n",
    "y = np.array([2, 3, 6, 7, 9, 10, 11])\n",
    "plt.scatter(x, y, s=20, c='black') # 점그래프\n",
    "plt.plot(x, x * 2 + 2) # x축, y 축 순서대로 전달\n",
    "plt.plot(x, x * 2 + 1) # x축, y 축 순서대로 전달\n",
    "plt.plot(x, x * 2) # x축, y 축 순서대로 전달\n",
    "plt.plot(x, x * 2 - 1) # x축, y 축 순서대로 전달\n",
    "plt.plot(x, x * 2 - 2) # x축, y 축 순서대로 전달\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 샘플예제에서 $f(x) = 2x$ 가 가장 데이터를 잘 설명하는 직선이 된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습(traing, fitting)\n",
    "회귀모델의 학습은 회귀모델에 포함된 계수인 $\\beta_0$ 와 $\\beta_1$을 추정한다.  \n",
    "최소자승법(least square method): 회귀모델은 오차의 제곱합을 최소화하는 방향으로 계수를 추정.  \n",
    "\n",
    "#### 비용 함수 (cost function)\n",
    "$$ Cost = {1\\over2n} \\sum_i^n{(y_i - \\hat y_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.919417Z",
     "start_time": "2023-03-30T08:09:48.917711Z"
    }
   },
   "outputs": [],
   "source": [
    "# 가정에 따른 함수 h 정의\n",
    "def h1(x):\n",
    "    return 2 * x + 2\n",
    "def h2(x):\n",
    "    return 2 * x + 1\n",
    "def h3(x):\n",
    "    return 2 * x\n",
    "def h4(x):\n",
    "    return 2 * x - 1\n",
    "def h5(x):\n",
    "    return 2 * x - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.922630Z",
     "start_time": "2023-03-30T08:09:48.921304Z"
    }
   },
   "outputs": [],
   "source": [
    "# 비용함수 j\n",
    "def j(x, y, h):\n",
    "    return sum((y - h(x)) ** 2) / (2 * len(x))\n",
    "# sum 합계, len갯수를 세어주는 파이썬 명령어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.924817Z",
     "start_time": "2023-03-30T08:09:48.923572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "0.8571428571428571\n",
      "0.21428571428571427\n",
      "0.5714285714285714\n",
      "1.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# 비용함수 결과출력\n",
    "print(j(x, y, h1))\n",
    "print(j(x, y, h2))\n",
    "print(j(x, y, h3))\n",
    "print(j(x, y, h4))\n",
    "print(j(x, y, h5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순선형회귀모델의 비용함수는 각 가정에 대한 비용함수의 결과의 집합이고 이를 2차원 평면상에 그려보면 2차 함수임을 확인 가능합니다.  \n",
    "<img src=\"./image/12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비용함수의 최소화, 경사하강법 (gradient decent)\n",
    "위에서 정의 된 비용함수 $ Cost = {1\\over2n} \\sum_i^n{(y_i - \\hat y_i)^2}$ 의 최소값을 찾기 위해서는 미분이 필요하다.\n",
    "\n",
    "<img src=\"./image/13.png\">\n",
    "비용함수의 미분값에 따라 추정하고자 하는 파라메터(X)를 미분값과 반대방향으로 움직이면서 비용함수의 최소값에 다다르게 함.  \n",
    "<img src=\"./image/14.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델의 평가\n",
    "선형회귀모델의 평가는 모델의 예측력, 그리고 모델의 설명력을 위한 평가방법으로 나눌 수 있습니다.  \n",
    "\n",
    "> **RMSE** : 평균제곱오차의 제곱근  \n",
    "예측모델에서 가장 많이 쓰이는 지표, 예측이 대략 평균적으로 RMSE만큼 오차가 난다고 해석합니다.\n",
    "  \n",
    "$$\\sqrt{{1\\over n}\\sum_i^n{(y_i - \\hat y_i)^2}}$$\n",
    "\n",
    "> **MAE** : 평균절대 오차  \n",
    "예측모델에서 종종 쓰이는 지표, 실제 예측값에 절대값을 씌워 예측결과 오차를 그대로 해석.  \n",
    "  \n",
    "$${1\\over n}\\sum_i^n{\\left\\vert(y_i - \\hat y_i)\\right\\vert}$$\n",
    "\n",
    "> **R2 score** : 결정계수 혹은 설명계수. 독립변수가 얼마나 종속변수를 잘 설명할 수 있는지 나타냄.  \n",
    "0과 1사이 범위에 있으며, 1에 가까울 수록 모델이 종속변수를 잘 설명한다고 해석한다.  \n",
    "일반적으로는 R2 score가 0.6 이상이여야 사용가능한 모델이라고 해석한다.\n",
    "\n",
    "<img src=\"./image/15.png\">\n",
    "\n",
    "$$SST = SSR + SSE$$  \n",
    "$$R^2 = 1 - {SSE \\over SST}$$  \n",
    "$$={SSR \\over SST}$$  \n",
    "$$={선형모형오차 \\over 전체오차}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중선형회귀모델 (Multiple Linear Regression)\n",
    "독립 변수가 둘 이상인 가장 일반적인 형태의 선형회귀모델\n",
    "  \n",
    "다중선형회귀모델의 구조는 아래와 같습니다.  \n",
    "\n",
    "# $$ y_i = \\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_p x_{i,p} + \\varepsilon_i  $$  \n",
    "\n",
    "> $\\beta_0$ : 절편  \n",
    "$\\beta_p$ : $p$번째 독립변수의 계수  \n",
    "$x_{i,p}$ : $i$ 번째 샘플의 $p$번째 독립변수 값  \n",
    "$y_i$ : $i$ 번째 샘플의 종속변수 값  \n",
    "$\\hat{y}_i$ : $i$ 번째 샘플의 종속변수 예측 값 ($\\hat{y}_i = \\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_p x_{i,p}$)  \n",
    "$\\varepsilon_i$ : $i$ 번째 샘플의 예측 오차 ($y_i - \\hat{y}_i$)\n",
    "\n",
    "행렬과 벡터를 이용한 표현으로 아래와 같이 표현이 가능합니다.\n",
    "\n",
    "# $$ y = X\\beta + \\varepsilon $$\n",
    "\n",
    "# $ y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots  \\\\ y_n\\end{pmatrix}$ $ X = \\begin{pmatrix} 1 & x_{1,1} & \\dots & x_{1,p} \\\\ 1 & x_{2,1} & \\dots & x_{2,p} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n,1} & \\dots & x_{n,p}\\end{pmatrix} $ $ \\beta = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\vdots  \\\\ \\beta_p\\end{pmatrix}$ $ \\varepsilon = \\begin{pmatrix} \\varepsilon_0 \\\\ \\varepsilon_1 \\\\ \\vdots  \\\\ \\varepsilon_n\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델학습 및 비용함수\n",
    "기본선형회귀모델과 마찬가지로 최소자승법을 사용합니다.\n",
    "\n",
    "#### 비용함수\n",
    "$$\\varepsilon = y - \\hat{y}$$  \n",
    "$$\\hat{y} = X\\beta$$  \n",
    "$$J = \\varepsilon^T\\varepsilon = (y - \\hat{y})^T(y - \\hat{y})$$  \n",
    "$$ =(y^T - \\beta^TX^T)(y - X\\beta) $$  \n",
    "$$ =y^Ty - y^TX\\beta - \\beta^TX^Ty + \\beta^TX^TX\\beta$$\n",
    "\n",
    "$$ {\\partial J \\over \\partial \\beta} = 0 \\Rightarrow \\beta = (X^TX)^{-1}X^Ty$$\n",
    "(행렬-벡터 미분 생략)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 선형 회귀 모델 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\studytsp86.edu\\\\Desktop\\\\강의자료_머신러닝 이해와 구현\\\\수강생공유용'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.927041Z",
     "start_time": "2023-03-30T08:09:48.925654Z"
    }
   },
   "outputs": [],
   "source": [
    "# boston 데이터 확인\n",
    "df = pd.read_csv('./data/boston.csv') # 로딩데이터 파일명을 경로포함한 문자열 형식으로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.929322Z",
     "start_time": "2023-03-30T08:09:48.927956Z"
    }
   },
   "outputs": [],
   "source": [
    "# 타겟데이터 분할\n",
    "y = df['y']\n",
    "X = df.drop('y', axis=1) # 열방향으로 작업하면서 y 삭제 후 남은 데이터 X에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.931679Z",
     "start_time": "2023-03-30T08:09:48.930167Z"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련셋과 테스트셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# X먼저, 학습데이터먼저 \n",
    "# test_size= 평가데이터비율 설정 0~1 사이 실수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.934012Z",
     "start_time": "2023-03-30T08:09:48.932621Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.938509Z",
     "start_time": "2023-03-30T08:09:48.936981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.941084Z",
     "start_time": "2023-03-30T08:09:48.939638Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.943278Z",
     "start_time": "2023-03-30T08:09:48.941908Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7112260057484923\n",
      "4.638689926172829\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가지표 출력\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(r2_score(y_test, pred))\n",
    "print(mean_squared_error(y_test, pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 해석\n",
    "# 0.711 보스턴주택가격의 변동분을 우리가 선택한 설명변수와 모델로 약 71.1% 설명이 가능하다.\n",
    "# RMSE y값이 만달러 모델의 예측값이 평균적으로 약 4.63만 달러 오차를 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:09:48.945418Z",
     "start_time": "2023-03-30T08:09:48.944063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.631084035692954,\n",
       " array([-1.33470103e-01,  3.58089136e-02,  4.95226452e-02,  3.11983512e+00,\n",
       "        -1.54170609e+01,  4.05719923e+00, -1.08208352e-02, -1.38599824e+00,\n",
       "         2.42727340e-01, -8.70223437e-03, -9.10685208e-01,  1.17941159e-02,\n",
       "        -5.47113313e-01]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 계수 확인\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베타 시각화\n",
    "# 막대그래프\n",
    "plt.bar(X_train.columns, model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베타 해석\n",
    "# RM 기준 베타값 해석\n",
    "#  y = b0 + b1x1 + b2x2....\n",
    "# 설명변수 RM의 숫자가 1 증가함에 따라 방 갯수가 하나 늘어날 때 마다 4.057만 달러 보스턴주택가격이 상승함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
